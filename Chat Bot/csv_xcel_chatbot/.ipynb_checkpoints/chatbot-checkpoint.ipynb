{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e42dd4-acca-43c0-bb8c-ada658d3f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet # to perform lemmitization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech\n",
    "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd844ebe-60ed-466e-8020-4258573bce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shubhamrathod/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shubhamrathod/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shubhamrathod/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shubhamrathod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "  \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0f894d-7209-4333-b1e3-c7863116e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e767815e-9487-41a8-94d1-23579a8463ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('OPTED-Dictionary.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46203a17-01bb-484a-9173-353c14e0fe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"The first letter of the English and of many o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"The name of the sixth tone in the model major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"An adjective  commonly called the indefinite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"In each; to or for each; as  \"\"\"\"twenty leagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"prep.\"</td>\n",
       "      <td>\"In; on; at; by.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word Count      POS                                         Definition\n",
       "0    A     1       \"\"  \"The first letter of the English and of many o...\n",
       "1    A     1       \"\"  \"The name of the sixth tone in the model major...\n",
       "2    A     1       \"\"  \"An adjective  commonly called the indefinite ...\n",
       "3    A     1       \"\"  \"In each; to or for each; as  \"\"\"\"twenty leagu...\n",
       "4    A     1  \"prep.\"                                  \"In; on; at; by.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad96849-3e72-47d4-86bd-be55cef88791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176009, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee1641-4bbd-4cda-8ecd-92945d194844",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a370143c-db75-4901-8623-bc9e438d66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Count', 'POS'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16175ba9-29e3-4c6e-a0a3-057e1fdeb1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>\"The first letter of the English and of many o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>\"The name of the sixth tone in the model major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>\"An adjective  commonly called the indefinite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>\"In each; to or for each; as  \"\"\"\"twenty leagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>\"In; on; at; by.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word                                         Definition\n",
       "0    A  \"The first letter of the English and of many o...\n",
       "1    A  \"The name of the sixth tone in the model major...\n",
       "2    A  \"An adjective  commonly called the indefinite ...\n",
       "3    A  \"In each; to or for each; as  \"\"\"\"twenty leagu...\n",
       "4    A                                  \"In; on; at; by.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95700407-e17e-46df-976d-d9e49eeef37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176009, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96619d6b-88bd-4bb9-a819-c66f037b0e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any() # check for null/ NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6baa8c-f1c4-49c9-a7ce-62a5c20faab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80809732-9e2d-46ae-ba57-ef281a77544c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176005, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89569110-2896-4ae7-afbb-01400e831b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "Definition    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # check for data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0d44e-d909-4fdc-a5f7-81a10330dcb8",
   "metadata": {},
   "source": [
    "# Lower Case Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ae4b9a-d77a-4bff-9d28-8da39b4234cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts text into lower case and removes special characters\n",
    "def txt_to_lower(x):\n",
    "    for i in x:\n",
    "        a=str(i).lower()\n",
    "        p=re.sub(r'[^a-z0-9]',' ',a)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0d8ff-b9aa-4bf1-8776-38b7a23d3697",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76314e65-664b-4e27-bb45-76ed21eee131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    text=str(text).lower() # text to lower case\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # word tokenizing\n",
    "    lema=wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "\n",
    "    tags_list=pos_tag(tokens,tagset=None) # parts of speech\n",
    "\n",
    "    lema_words=[]   # empty list \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' # Noun\n",
    "        lema_token=lema.lemmatize(token,pos_val) # performing lemmatization\n",
    "        lema_words.append(lema_token) # appending the lemmatized token into a list\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6e6932-e64e-430a-a9c4-a4cf245e2a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell you some stuff about me'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test Query\n",
    "text_normalization('telling you some stuff about me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31685d6e-4591-4904-af4d-39bfeef8e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text']=df['Word'].apply(text_normalization) # applying the fuction to the dataset to get clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c702dffc-306b-428a-b53d-198d06c229fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Definition</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>\"The first letter of the English and of many o...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>\"The name of the sixth tone in the model major...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>\"An adjective  commonly called the indefinite ...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>\"In each; to or for each; as  \"\"\"\"twenty leagu...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>\"In; on; at; by.\"</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word                                         Definition lemmatized_text\n",
       "0    A  \"The first letter of the English and of many o...               a\n",
       "1    A  \"The name of the sixth tone in the model major...               a\n",
       "2    A  \"An adjective  commonly called the indefinite ...               a\n",
       "3    A  \"In each; to or for each; as  \"\"\"\"twenty leagu...               a\n",
       "4    A                                  \"In; on; at; by.\"               a"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249c45f-a1b7-4633-a3f0-c0221687b895",
   "metadata": {},
   "source": [
    "# Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c568bc9f-5ea9-473e-8172-825712db3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fd484-2a4b-4976-90c2-f3499e4f99f5",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63de24d4-0f97-443e-8f9b-0f6d5dbf8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # intializing the count vectorizer\n",
    "\n",
    "X = cv.fit_transform(df['lemmatized_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6443891-b8e2-46f5-8bbb-05b3b05715bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the unique word from data \n",
    "\n",
    "features = cv.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcc9a928-7738-4d93-8926-84205627a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aam</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aardwolf</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronic</th>\n",
       "      <th>aaronical</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaca</th>\n",
       "      <th>abacinate</th>\n",
       "      <th>abacination</th>\n",
       "      <th>...</th>\n",
       "      <th>zymometer</th>\n",
       "      <th>zymophyte</th>\n",
       "      <th>zymose</th>\n",
       "      <th>zymosimeter</th>\n",
       "      <th>zymosis</th>\n",
       "      <th>zymotic</th>\n",
       "      <th>zyophyte</th>\n",
       "      <th>zythem</th>\n",
       "      <th>zythepsary</th>\n",
       "      <th>zythum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aam  aardvark  aardwolf  aaron  aaronic  aaronical  ab  abaca  abacinate  \\\n",
       "0    0         0         0      0        0          0   0      0          0   \n",
       "1    0         0         0      0        0          0   0      0          0   \n",
       "2    0         0         0      0        0          0   0      0          0   \n",
       "3    0         0         0      0        0          0   0      0          0   \n",
       "4    0         0         0      0        0          0   0      0          0   \n",
       "\n",
       "   abacination  ...  zymometer  zymophyte  zymose  zymosimeter  zymosis  \\\n",
       "0            0  ...          0          0       0            0        0   \n",
       "1            0  ...          0          0       0            0        0   \n",
       "2            0  ...          0          0       0            0        0   \n",
       "3            0  ...          0          0       0            0        0   \n",
       "4            0  ...          0          0       0            0        0   \n",
       "\n",
       "   zymotic  zyophyte  zythem  zythepsary  zythum  \n",
       "0        0         0       0           0       0  \n",
       "1        0         0       0           0       0  \n",
       "2        0         0       0           0       0  \n",
       "3        0         0       0           0       0  \n",
       "4        0         0       0           0       0  \n",
       "\n",
       "[5 rows x 99059 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bae70e9-7bd4-4c73-b8fc-043135769ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question ='Meaning of a AAM' # considering an example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0a90c6-047d-4e64-9978-1e4223912980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for stop words\n",
    "\n",
    "Q=[]\n",
    "a=Question.split()\n",
    "for i in a:\n",
    "    if i in stop:\n",
    "        continue\n",
    "    else:\n",
    "        Q.append(i)\n",
    "    b=\" \".join(Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f12b4e59-15e6-455f-9627-58f9b7e7bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_lemma = text_normalization(b) # applying the function that we created for text normalizing\n",
    "\n",
    "Question_bow = cv.transform([Question_lemma]).toarray() # applying bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3137595-8942-4615-abdb-a9ba60a65306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc476db8-d189-4087-b79d-dca5b8c56cb3",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "782ac157-e44e-4c27-8a65-cc896aa2a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity for the above question we considered.\n",
    "\n",
    "# cosine_value = 1- pairwise_distances(df_bow, Question_bow, metric = 'cosine' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3a74316-7aca-4d07-8907-a47f33e2c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_value = cosine_value.argmax() # returns the index number of highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d364f7-a33b-4b3c-b461-2076e8abf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf-idf\n",
    "\n",
    "tfidf = TfidfVectorizer() # intializing tf-id \n",
    "x_tfidf = tfidf.fit_transform(df['lemmatized_text']).toarray() # transforming the data into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148fdd33-effc-4d0c-ab23-a22a40995c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aam</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aardwolf</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronic</th>\n",
       "      <th>aaronical</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaca</th>\n",
       "      <th>abacinate</th>\n",
       "      <th>abacination</th>\n",
       "      <th>...</th>\n",
       "      <th>zymometer</th>\n",
       "      <th>zymophyte</th>\n",
       "      <th>zymose</th>\n",
       "      <th>zymosimeter</th>\n",
       "      <th>zymosis</th>\n",
       "      <th>zymotic</th>\n",
       "      <th>zyophyte</th>\n",
       "      <th>zythem</th>\n",
       "      <th>zythepsary</th>\n",
       "      <th>zythum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aam  aardvark  aardwolf  aaron  aaronic  aaronical   ab  abaca  abacinate  \\\n",
       "0  0.0       0.0       0.0    0.0      0.0        0.0  0.0    0.0        0.0   \n",
       "1  0.0       0.0       0.0    0.0      0.0        0.0  0.0    0.0        0.0   \n",
       "2  0.0       0.0       0.0    0.0      0.0        0.0  0.0    0.0        0.0   \n",
       "3  0.0       0.0       0.0    0.0      0.0        0.0  0.0    0.0        0.0   \n",
       "4  0.0       0.0       0.0    0.0      0.0        0.0  0.0    0.0        0.0   \n",
       "\n",
       "   abacination  ...  zymometer  zymophyte  zymose  zymosimeter  zymosis  \\\n",
       "0          0.0  ...        0.0        0.0     0.0          0.0      0.0   \n",
       "1          0.0  ...        0.0        0.0     0.0          0.0      0.0   \n",
       "2          0.0  ...        0.0        0.0     0.0          0.0      0.0   \n",
       "3          0.0  ...        0.0        0.0     0.0          0.0      0.0   \n",
       "4          0.0  ...        0.0        0.0     0.0          0.0      0.0   \n",
       "\n",
       "   zymotic  zyophyte  zythem  zythepsary  zythum  \n",
       "0      0.0       0.0     0.0         0.0     0.0  \n",
       "1      0.0       0.0     0.0         0.0     0.0  \n",
       "2      0.0       0.0     0.0         0.0     0.0  \n",
       "3      0.0       0.0     0.0         0.0     0.0  \n",
       "4      0.0       0.0     0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 99059 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns all the unique word from data with a score of that word\n",
    "\n",
    "df_tfidf = pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names_out()) \n",
    "\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "660d94de-333c-4d3a-945b-0521d0f5bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using tf-idf\n",
    "\n",
    "def chat_tfidf(text):\n",
    "    lemma=text_normalization(text) # calling the function to perform text normalization\n",
    "    \n",
    "    tf = tfidf.transform([lemma]).toarray() # applying tf-idf\n",
    "    \n",
    "    cos = 1 - pairwise_distances(df_tfidf, tf, metric='cosine') # applying cosine similarity\n",
    "    index_value = cos.argmax() # getting index value \n",
    "    \n",
    "    return df['Text Response'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d9fb0-16b1-4de8-a53e-e84929d6e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_tfidf(\"What is AAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aba3f1-d8db-499a-babc-d514366aefd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
